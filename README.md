# Swin UNETR-mini
Knowledge Distillation for Efficient 3D Medical Image Segmentation

We have the weights learned weights of the Swin UNETR and Swin UNETR Mini models respectively in the links to the Kaggle dataset hosting bebpages below:

https://www.kaggle.com/models/therealcyberlord/swin-unetr-brats

https://www.kaggle.com/models/therealcyberlord/swin-unetr-mini


Xingyu contributions: formulated the project idea, and created the distillation loss training loop.

Matt contributions: wrote the dataset subsampling and determining FLOPs

Sakshi contributions: ran experiments and plotted graphs

Since we don't have lines because of the jupyter notebook format, it is hard to give a specific line number
